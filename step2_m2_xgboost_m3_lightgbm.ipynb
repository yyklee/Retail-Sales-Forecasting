{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: XGBoost\n",
    "\n",
    "__Date Features__: Integration of date-specific features to leverage chronological information.\n",
    "\n",
    "__Normalization__: Not required in XGBoost, as it's an ensemble model of decision trees, which are scale-invariant.\n",
    "\n",
    "__Hyperparameter Tuning__:\n",
    "Exploring a wide range of major parameters increases the likelihood of identifying the optimal set of hyperparameters.\n",
    "\n",
    "- `n_estimators`: Searching from 500 to 3000 decision trees.\n",
    "- `learning_rate`: Varying from 0.01 to 0.1.\n",
    "- `subsample`: Fraction of data used ranges from 50% to 100%.\n",
    "- `gamma`: Set between 0 to 0.5.\n",
    "- `min_child_weight`: Varies from 1 to 6 for each leaf node.\n",
    "- `max_depth`: Tree depth ranging from 5 to 50.\n",
    "- `lambda`: L2 regularization parameter from 0.25 to 1.\n",
    "- `alpha`: L1 regularization parameter also from 0.25 to 1.\n",
    "\n",
    "\n",
    "### Model 3: LightGBM\n",
    "\n",
    "__Date Features__: Integration of date-specific features to leverage chronological information.\n",
    "\n",
    "__Normalization__: Since `lightGBM` is an ensemble model of decision trees we do not need to normalize our data.\n",
    "\n",
    "__Hyperparameter Tuning__: In `lightGBM` we explore the following hyperparamters:\n",
    "- `num_leaves`: We vary the number of leaves in each tree from 5 to 500.\n",
    "- `learning_rate`: The learning rate of the `lightGBM` model varies from 0.001 to 0.2\n",
    "- `max_depth`: We vary the depth of the decision tree from 5 to 50\n",
    "- `n_estimators`: The number of estimator trees varies from 500 to 3000\n",
    "- `min_child_samples`: We vary the minimum child samples required in each tree from 0.001 to 0.2\n",
    "- `reg_lambda`: The L2 regularization parameter varies from 0.1 to 1\n",
    "- `reg_alpha`: The L2 regularization parameter varies from 0.1 to 1\n",
    "- `colsample_bytree`: We vary the number of features taken in a tree from 0.5 (50% of all the features) to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import plot_importance, plot_tree\n",
    "\n",
    "# main module for evaluation\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# main modules for designing ML pipelines\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# time-related feature engineering\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# others\n",
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "import gc\n",
    "from itertools import product\n",
    "import optuna\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>typeholiday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>typestores</th>\n",
       "      <th>cluster</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      family  sales  onpromotion typeholiday  dcoilwtico   city  \\\n",
       "0 2013-01-01  AUTOMOTIVE    0.0            0     Holiday       93.14  Quito   \n",
       "1 2013-01-01   BABY CARE    0.0            0     Holiday       93.14  Quito   \n",
       "2 2013-01-01      BEAUTY    0.0            0     Holiday       93.14  Quito   \n",
       "3 2013-01-01   BEVERAGES    0.0            0     Holiday       93.14  Quito   \n",
       "4 2013-01-01       BOOKS    0.0            0     Holiday       93.14  Quito   \n",
       "\n",
       "       state typestores  cluster  day_of_week  month  year  \n",
       "0  Pichincha          D       13            2      1  2013  \n",
       "1  Pichincha          D       13            2      1  2013  \n",
       "2  Pichincha          D       13            2      1  2013  \n",
       "3  Pichincha          D       13            2      1  2013  \n",
       "4  Pichincha          D       13            2      1  2013  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle('processed_data/train_df.pkl')\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = ['sales']\n",
    "\n",
    "TARGET_ENCODE_COLUMNS = ['family', 'cluster']\n",
    "\n",
    "CATEGORY_COLUMNS = ['typeholiday','city', 'typestores', 'year']\n",
    "\n",
    "TIME_COLUMNS = ['day_of_week', 'month']\n",
    "\n",
    "COL_NAMES_ORIGINAL = ['family', 'typeholiday','onpromotion', 'dcoilwtico', 'city', 'typestores',\n",
    "                    'cluster', 'year', 'day_of_week','month']\n",
    "\n",
    "COL_NAMES_AFTER_TRANS=['target_trans__family', 'target_trans__cluster',\n",
    "       'category_trans__typeholiday_Additional',\n",
    "       'category_trans__typeholiday_Bridge',\n",
    "       'category_trans__typeholiday_Event',\n",
    "       'category_trans__typeholiday_Holiday',\n",
    "       'category_trans__typeholiday_NDay',\n",
    "       'category_trans__typeholiday_Transfer',\n",
    "       'category_trans__city_Ambato', 'category_trans__city_Babahoyo',\n",
    "       'category_trans__city_Cayambe', 'category_trans__city_Cuenca',\n",
    "       'category_trans__city_Daule', 'category_trans__city_El Carmen',\n",
    "       'category_trans__city_Esmeraldas', 'category_trans__city_Guaranda',\n",
    "       'category_trans__city_Guayaquil', 'category_trans__city_Ibarra',\n",
    "       'category_trans__city_Latacunga', 'category_trans__city_Libertad',\n",
    "       'category_trans__city_Loja', 'category_trans__city_Machala',\n",
    "       'category_trans__city_Manta', 'category_trans__city_Playas',\n",
    "       'category_trans__city_Puyo', 'category_trans__city_Quevedo',\n",
    "       'category_trans__city_Quito', 'category_trans__city_Riobamba',\n",
    "       'category_trans__city_Salinas',\n",
    "       'category_trans__city_Santo Domingo',\n",
    "       'category_trans__typestores_A', 'category_trans__typestores_B',\n",
    "       'category_trans__typestores_C', 'category_trans__typestores_D',\n",
    "       'category_trans__typestores_E', 'category_trans__year_2013',\n",
    "       'category_trans__year_2014', 'category_trans__year_2015',\n",
    "       'category_trans__year_2016', 'category_trans__year_2017',\n",
    "       'time_trans__day_of_week_sin__day_of_week',\n",
    "       'time_trans__day_of_week_cos__day_of_week',\n",
    "       'time_trans__month_sin__month', 'time_trans__month_cos__month',\n",
    "       'time_trans__day_of_week_sin__day_of_week day_of_week_cos__day_of_week',\n",
    "       'time_trans__day_of_week_sin__day_of_week month_sin__month',\n",
    "       'time_trans__day_of_week_sin__day_of_week month_cos__month',\n",
    "       'time_trans__day_of_week_cos__day_of_week month_sin__month',\n",
    "       'time_trans__day_of_week_cos__day_of_week month_cos__month',\n",
    "       'time_trans__month_sin__month month_cos__month',\n",
    "       'remainder__onpromotion', 'remainder__dcoilwtico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[COL_NAMES_ORIGINAL]\n",
    "y = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Preprocess Pipeline\n",
    "\n",
    "\n",
    "**1. Transforming Standard Date Representation**:\n",
    "  - Standard Date represents days of the week as 0 (Sunday) to 6 (Saturday). This incorrectly implies a linear relationship between days, failing to capture their cyclical nature.\n",
    "  - Transform via sine.cosine and added interaction using polynomial features.\n",
    "\n",
    "**2. Target Encoding**:\n",
    "  - Used for product categories and clusters.\n",
    "  - This method involves replacing a categorical value with the mean of the target variable for that category. For instance, in the context of product categories, each category is replaced with the average size or another relevant metric from the training dataset.\n",
    "  - To prevent data leakage, the encoding is fit on the training set and then applied to other datasets without refitting.\n",
    "\n",
    "**3. One-Hot Encoding**:\n",
    "  - Creates binary columns for categories such as holiday type.\n",
    "  - These models, being tree-based, can handle categorical data inherently. However, one-hot encoding is still used due to its ability to create explicit feature representations, making the model more interpretable and sometimes improving performance by handling categories with very few occurrences more effectively.\n",
    "\n",
    "\n",
    "**4. Add Lag Features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for target encoding category features\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "target_encoder = TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to be able to get feature names out of functional transformer \n",
    "def f_out(self,input_features):\n",
    "    return input_features\n",
    "\n",
    "# functions to transform time features with sine cosine transformation \n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi), feature_names_out=f_out)\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi), feature_names_out=f_out)\n",
    "\n",
    "## time feat pipeline: to avoid jump between first and last value of periodic range\n",
    "## (1) sine/cosine transformation from ordinal features to trigonometric features\n",
    "## (2) polynomial transformation to captrue linear interactions between time features\n",
    "time_feat = make_pipeline(\n",
    "                ColumnTransformer([\n",
    "                            (\"day_of_week_sin\", sin_transformer(7), [\"day_of_week\"]),\n",
    "                            (\"day_of_week_cos\", cos_transformer(7), [\"day_of_week\"]),\n",
    "                            (\"month_sin\", sin_transformer(12), [\"month\"]),\n",
    "                            (\"month_cos\", cos_transformer(12), [\"month\"])\n",
    "                            ],remainder='drop'),\n",
    "                PolynomialFeatures(degree=2, interaction_only=True, include_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the pipeline to perform feature engineering\n",
    "preprocess_pipe = Pipeline(steps=[\n",
    "    ('encoder', ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        (\"target_trans\", target_encoder, TARGET_ENCODE_COLUMNS),\n",
    "                        (\"category_trans\", one_hot_encoder, CATEGORY_COLUMNS),\n",
    "                        (\"time_trans\",time_feat,TIME_COLUMNS),\n",
    "                                ],\n",
    "                                remainder=\"passthrough\", verbose_feature_names_out=True\n",
    "                            )),\n",
    "    (\"pandarizer2\", FunctionTransformer(lambda x: pd.DataFrame(x, columns = COL_NAMES_AFTER_TRANS)))\n",
    "                            ],verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-08-15 00:00:00')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end_date = '2017-06-30'\n",
    "val_start_date = '2017-07-01'\n",
    "val_end_date = '2017-08-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.set_index('date', inplace = True)\n",
    "X.index = train_df.index\n",
    "y.index = train_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_end_date, val_start_date, val_end_date):\n",
    "    \n",
    "    # Split Dataset\n",
    "    train_data = df[:train_end_date]\n",
    "    validation_data = df[val_start_date:val_end_date]\n",
    "    \n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training and validation sets\n",
    "X_train, X_val = train_test_split(X, train_end_date, val_start_date, val_end_date)\n",
    "y_train, y_val = train_test_split(y, train_end_date, val_start_date, val_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........... (step 1 of 2) Processing encoder, total=   4.5s\n",
      "[Pipeline] ....... (step 2 of 2) Processing pandarizer2, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;target_trans&#x27;,\n",
       "                                                  TargetEncoder(),\n",
       "                                                  [&#x27;family&#x27;, &#x27;cluster&#x27;]),\n",
       "                                                 (&#x27;category_trans&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;typeholiday&#x27;, &#x27;city&#x27;,\n",
       "                                                   &#x27;typestores&#x27;, &#x27;year&#x27;]),\n",
       "                                                 (&#x27;time_trans&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                                                   ColumnTransformer(transformers=[(&#x27;day_of_...\n",
       "                                                                                                    FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                                                                                        func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A660&gt;),\n",
       "                                                                                                    [&#x27;month&#x27;])])),\n",
       "                                                                  (&#x27;polynomialfeatures&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                                      interaction_only=True))]),\n",
       "                                                  [&#x27;day_of_week&#x27;, &#x27;month&#x27;])])),\n",
       "                (&#x27;pandarizer2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001BB9602A2A0&gt;))],\n",
       "         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;encoder&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;target_trans&#x27;,\n",
       "                                                  TargetEncoder(),\n",
       "                                                  [&#x27;family&#x27;, &#x27;cluster&#x27;]),\n",
       "                                                 (&#x27;category_trans&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;typeholiday&#x27;, &#x27;city&#x27;,\n",
       "                                                   &#x27;typestores&#x27;, &#x27;year&#x27;]),\n",
       "                                                 (&#x27;time_trans&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                                                   ColumnTransformer(transformers=[(&#x27;day_of_...\n",
       "                                                                                                    FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                                                                                        func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A660&gt;),\n",
       "                                                                                                    [&#x27;month&#x27;])])),\n",
       "                                                                  (&#x27;polynomialfeatures&#x27;,\n",
       "                                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                                      interaction_only=True))]),\n",
       "                                                  [&#x27;day_of_week&#x27;, &#x27;month&#x27;])])),\n",
       "                (&#x27;pandarizer2&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001BB9602A2A0&gt;))],\n",
       "         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoder: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;target_trans&#x27;, TargetEncoder(),\n",
       "                                 [&#x27;family&#x27;, &#x27;cluster&#x27;]),\n",
       "                                (&#x27;category_trans&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;typeholiday&#x27;, &#x27;city&#x27;, &#x27;typestores&#x27;, &#x27;year&#x27;]),\n",
       "                                (&#x27;time_trans&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                                  ColumnTransformer(transformers=[(&#x27;day_of_week_sin&#x27;,\n",
       "                                                                                   FunctionTransform...\n",
       "                                                                                                       func=&lt;function sin_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A5C0&gt;),\n",
       "                                                                                   [&#x27;month&#x27;]),\n",
       "                                                                                  (&#x27;month_cos&#x27;,\n",
       "                                                                                   FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                                                                       func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A660&gt;),\n",
       "                                                                                   [&#x27;month&#x27;])])),\n",
       "                                                 (&#x27;polynomialfeatures&#x27;,\n",
       "                                                  PolynomialFeatures(include_bias=False,\n",
       "                                                                     interaction_only=True))]),\n",
       "                                 [&#x27;day_of_week&#x27;, &#x27;month&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">target_trans</label><div class=\"sk-toggleable__content\"><pre>[&#x27;family&#x27;, &#x27;cluster&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">category_trans</label><div class=\"sk-toggleable__content\"><pre>[&#x27;typeholiday&#x27;, &#x27;city&#x27;, &#x27;typestores&#x27;, &#x27;year&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">time_trans</label><div class=\"sk-toggleable__content\"><pre>[&#x27;day_of_week&#x27;, &#x27;month&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;day_of_week_sin&#x27;,\n",
       "                                 FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                     func=&lt;function sin_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A480&gt;),\n",
       "                                 [&#x27;day_of_week&#x27;]),\n",
       "                                (&#x27;day_of_week_cos&#x27;,\n",
       "                                 FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                     func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambd...\n",
       "                                 [&#x27;day_of_week&#x27;]),\n",
       "                                (&#x27;month_sin&#x27;,\n",
       "                                 FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                     func=&lt;function sin_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A5C0&gt;),\n",
       "                                 [&#x27;month&#x27;]),\n",
       "                                (&#x27;month_cos&#x27;,\n",
       "                                 FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                                                     func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A660&gt;),\n",
       "                                 [&#x27;month&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">day_of_week_sin</label><div class=\"sk-toggleable__content\"><pre>[&#x27;day_of_week&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                    func=&lt;function sin_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A480&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">day_of_week_cos</label><div class=\"sk-toggleable__content\"><pre>[&#x27;day_of_week&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                    func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A520&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">month_sin</label><div class=\"sk-toggleable__content\"><pre>[&#x27;month&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                    func=&lt;function sin_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A5C0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">month_cos</label><div class=\"sk-toggleable__content\"><pre>[&#x27;month&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(feature_names_out=&lt;function f_out at 0x000001BB9602A160&gt;,\n",
       "                    func=&lt;function cos_transformer.&lt;locals&gt;.&lt;lambda&gt; at 0x000001BB9602A660&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False, interaction_only=True)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;onpromotion&#x27;, &#x27;dcoilwtico&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001BB9602A2A0&gt;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('encoder',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('target_trans',\n",
       "                                                  TargetEncoder(),\n",
       "                                                  ['family', 'cluster']),\n",
       "                                                 ('category_trans',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                sparse_output=False),\n",
       "                                                  ['typeholiday', 'city',\n",
       "                                                   'typestores', 'year']),\n",
       "                                                 ('time_trans',\n",
       "                                                  Pipeline(steps=[('columntransformer',\n",
       "                                                                   ColumnTransformer(transformers=[('day_of_...\n",
       "                                                                                                    FunctionTransformer(feature_names_out=<function f_out at 0x000001BB9602A160>,\n",
       "                                                                                                                        func=<function cos_transformer.<locals>.<lambda> at 0x000001BB9602A660>),\n",
       "                                                                                                    ['month'])])),\n",
       "                                                                  ('polynomialfeatures',\n",
       "                                                                   PolynomialFeatures(include_bias=False,\n",
       "                                                                                      interaction_only=True))]),\n",
       "                                                  ['day_of_week', 'month'])])),\n",
       "                ('pandarizer2',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x000001BB9602A2A0>))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pipe.fit(X_train[COL_NAMES_ORIGINAL], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_pipe.transform(X_train[COL_NAMES_ORIGINAL])\n",
    "X_val = preprocess_pipe.transform(X_val[COL_NAMES_ORIGINAL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping call back to avoid xgboost overfitting \n",
    "early_stop = xgb.callback.EarlyStopping(rounds = 10, \n",
    "                                        metric_name = 'rmse', \n",
    "                                        maximize = False,\n",
    "                                        save_best = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None,\n",
       "             callbacks=[&lt;xgboost.callback.EarlyStopping object at 0x000001D133265AC0&gt;],\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;gpu&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None,\n",
       "             callbacks=[&lt;xgboost.callback.EarlyStopping object at 0x000001D133265AC0&gt;],\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=&#x27;gpu&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None,\n",
       "             callbacks=[<xgboost.callback.EarlyStopping object at 0x000001D133265AC0>],\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device='gpu', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=5000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training xgboost model\n",
    "xgboost_base=XGBRegressor(random_state=42,verbosity=0, n_jobs = -1, reg_lambda=0.005, \n",
    "                         learning_rate=0.01, device='gpu',\n",
    "                          n_estimators=5000, objective='reg:squarederror',\n",
    "                        callbacks=[early_stop])\n",
    "xgboost_base.fit(X_train, y_train, eval_set=[(X_val, y_val)],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ploting feature importances\n",
    "_ = plot_importance(xgboost_base,max_num_features = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, name='xgb'):\n",
    "\n",
    "    params = param = {\n",
    "        'tree_method':'gpu_hist',  \n",
    "        'lambda': trial.suggest_loguniform(\n",
    "            'lambda', 1e-3, 10.0\n",
    "        ),\n",
    "        'alpha': trial.suggest_loguniform(\n",
    "            'alpha', 1e-3, 10.0\n",
    "        ),\n",
    "        'eta': trial.suggest_float('eta', 1e-5, 0.1),\n",
    "        'colsample_bytree': trial.suggest_categorical(\n",
    "            'colsample_bytree', [0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "        ),\n",
    "        'subsample': trial.suggest_categorical( \n",
    "            'subsample', [0.6,0.7,0.8,1.0]\n",
    "        ),\n",
    "        'learning_rate': trial.suggest_categorical(\n",
    "            'learning_rate', [0.009,0.01,0.012,0.016, 0.02]\n",
    "        ),\n",
    "        'n_estimators': trial.suggest_categorical(\n",
    "            \"n_estimators\", [150, 200, 300,500,1000]\n",
    "        ),\n",
    "        'max_depth': trial.suggest_categorical(\n",
    "            'max_depth', [4,5,7,9,11,13,17]\n",
    "        ),\n",
    "        'random_state': 42,\n",
    "        'min_child_weight': trial.suggest_int(\n",
    "            'min_child_weight', 1, 300\n",
    "        ),\n",
    "        'random_state':10\n",
    "        }\n",
    "\n",
    "    model =  XGBRegressor(**params)\n",
    "    model.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=50,verbose=False)\n",
    "\n",
    "    predictions_train = [a if a>0 else 0 for a in model.predict(X_train)]\n",
    "    predictions_val  = [a if a>0 else 0 for a in model.predict(X_val)]           \n",
    "    \n",
    "    train_score = np.round(mean_squared_log_error(y_train, predictions_train), 5)\n",
    "    test_score = np.round(mean_squared_log_error(y_val, predictions_val), 5)\n",
    "    train_score = np.sqrt(train_score)\n",
    "    test_score = np.sqrt(test_score)\n",
    "                  \n",
    "    print(f'TRAIN RMSLE : {train_score} || TEST RMSLE : {test_score}')\n",
    "                  \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:30:37,061] A new study created in memory with name: no-name-fe31b912-5573-4a6f-98bf-6b1e2f5d785e\n",
      "[I 2024-01-06 09:32:03,937] Trial 0 finished with value: 0.97306731524597 and parameters: {'lambda': 0.021139977347579934, 'alpha': 0.002496560094196592, 'eta': 0.07046715033128446, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 213}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3030579419196984 || TEST RMSLE : 0.97306731524597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:32:37,904] Trial 1 finished with value: 2.105870366380609 and parameters: {'lambda': 0.015440297217742456, 'alpha': 4.196673270867994, 'eta': 0.01060684925506165, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.009, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 199}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.7353592085866896 || TEST RMSLE : 2.105870366380609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:33:13,376] Trial 2 finished with value: 2.384738979427308 and parameters: {'lambda': 0.002096362386949793, 'alpha': 0.01664320359567732, 'eta': 0.00852965310993996, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 150, 'max_depth': 13, 'min_child_weight': 58}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 3.0044184129378517 || TEST RMSLE : 2.384738979427308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:34:38,983] Trial 3 finished with value: 1.5276354277117299 and parameters: {'lambda': 9.023885891208458, 'alpha': 0.6347780633801201, 'eta': 0.0004109864461965835, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 17, 'min_child_weight': 79}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.0451356923197053 || TEST RMSLE : 1.5276354277117299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:35:10,680] Trial 4 finished with value: 1.2145863493387368 and parameters: {'lambda': 0.02347616247012553, 'alpha': 0.004711336214241414, 'eta': 0.08434136043824347, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 250}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.8481450159551873 || TEST RMSLE : 1.2145863493387368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:35:59,232] Trial 5 finished with value: 1.3936642350293702 and parameters: {'lambda': 1.2347475635493264, 'alpha': 0.007820517516755, 'eta': 0.06654823418638965, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 5, 'min_child_weight': 66}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.735381802370879 || TEST RMSLE : 1.3936642350293702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:36:59,957] Trial 6 finished with value: 1.3870436186364148 and parameters: {'lambda': 0.11624075702580243, 'alpha': 1.73940927291919, 'eta': 0.0865584683111688, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 300, 'max_depth': 13, 'min_child_weight': 31}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.8650844484902018 || TEST RMSLE : 1.3870436186364148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:37:24,974] Trial 7 finished with value: 1.4044109085306906 and parameters: {'lambda': 1.236940248249391, 'alpha': 0.0030715638666301416, 'eta': 0.02808477345213231, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 300, 'max_depth': 4, 'min_child_weight': 283}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.9767877984245046 || TEST RMSLE : 1.4044109085306906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:37:56,760] Trial 8 finished with value: 1.1434509171800948 and parameters: {'lambda': 0.26394076329099936, 'alpha': 4.806409200833016, 'eta': 0.09456567936668088, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.016, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 46}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.668849903376574 || TEST RMSLE : 1.1434509171800948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:38:26,642] Trial 9 finished with value: 1.9368866771187208 and parameters: {'lambda': 0.04514979516234375, 'alpha': 0.32368982540304453, 'eta': 0.07155182579006836, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 207}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.5174193135034137 || TEST RMSLE : 1.9368866771187208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:39:25,475] Trial 10 finished with value: 1.4157612793122998 and parameters: {'lambda': 0.0017875474061058785, 'alpha': 0.0537045559366739, 'eta': 0.047119292369466145, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 7, 'min_child_weight': 163}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7041038700736526 || TEST RMSLE : 1.4157612793122998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:39:56,486] Trial 11 finished with value: 1.4885059623662917 and parameters: {'lambda': 0.34095387941669225, 'alpha': 0.08681782685429891, 'eta': 0.09789233603194603, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 126}. Best is trial 0 with value: 0.97306731524597.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.9294299676329276 || TEST RMSLE : 1.4885059623662917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:40:45,366] Trial 12 finished with value: 0.842531898505926 and parameters: {'lambda': 0.0076989187393306105, 'alpha': 0.0010522989434772285, 'eta': 0.05844334492928936, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.016, 'n_estimators': 500, 'max_depth': 11, 'min_child_weight': 126}. Best is trial 12 with value: 0.842531898505926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.27849520922059 || TEST RMSLE : 0.842531898505926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:41:28,328] Trial 13 finished with value: 0.983671693198498 and parameters: {'lambda': 0.0058368301468643465, 'alpha': 0.0011199775132303908, 'eta': 0.05174833711031827, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 11, 'min_child_weight': 125}. Best is trial 12 with value: 0.842531898505926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3748563561332507 || TEST RMSLE : 0.983671693198498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:42:35,071] Trial 14 finished with value: 0.8006872048434395 and parameters: {'lambda': 0.010379567864562813, 'alpha': 0.00118840235381704, 'eta': 0.052722138063083124, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 186}. Best is trial 14 with value: 0.8006872048434395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2409673645990857 || TEST RMSLE : 0.8006872048434395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:43:01,475] Trial 15 finished with value: 1.8488023150136956 and parameters: {'lambda': 0.0065462765930977525, 'alpha': 0.0010068250629216408, 'eta': 0.04469692325176845, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.016, 'n_estimators': 150, 'max_depth': 11, 'min_child_weight': 146}. Best is trial 14 with value: 0.8006872048434395.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.4332591312887333 || TEST RMSLE : 1.8488023150136956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:45:49,317] Trial 16 finished with value: 0.7403985413275744 and parameters: {'lambda': 0.005152375904292122, 'alpha': 0.02377719983124111, 'eta': 0.03248565402755877, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 94}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.133988536097257 || TEST RMSLE : 0.7403985413275744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:50:25,269] Trial 17 finished with value: 1.2799140596149414 and parameters: {'lambda': 0.0016046178616332804, 'alpha': 0.021727069734195942, 'eta': 0.03364685880437113, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 8}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.764735107601138 || TEST RMSLE : 1.2799140596149414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:54:15,011] Trial 18 finished with value: 1.0054750121211367 and parameters: {'lambda': 0.05500585233210901, 'alpha': 0.029790522936803714, 'eta': 0.03241905749036395, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 175}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3525494445675545 || TEST RMSLE : 1.0054750121211367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:55:40,684] Trial 19 finished with value: 1.4671332591145223 and parameters: {'lambda': 0.0045777381936909205, 'alpha': 0.24803229272639907, 'eta': 0.019181357880471556, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 98}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.652019975666154 || TEST RMSLE : 1.4671332591145223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:56:35,376] Trial 20 finished with value: 1.2464509617309458 and parameters: {'lambda': 0.012739125823030313, 'alpha': 0.01480339236590088, 'eta': 0.039353455881324224, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 4, 'min_child_weight': 249}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.76828447937542 || TEST RMSLE : 1.2464509617309458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 09:57:25,415] Trial 21 finished with value: 0.9612855975203207 and parameters: {'lambda': 0.003937519209997551, 'alpha': 0.00248208502243675, 'eta': 0.061456289609503466, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.016, 'n_estimators': 500, 'max_depth': 7, 'min_child_weight': 104}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.489278348731358 || TEST RMSLE : 0.9612855975203207\n",
      "TRAIN RMSLE : 1.3720787149431333 || TEST RMSLE : 0.9672021505352436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:00:23,356] Trial 22 finished with value: 0.9672021505352436 and parameters: {'lambda': 0.0010965738758781836, 'alpha': 0.006905226430745995, 'eta': 0.05788490525584511, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.009, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 135}. Best is trial 16 with value: 0.7403985413275744.\n",
      "[I 2024-01-06 10:01:19,285] Trial 23 finished with value: 0.769798674979374 and parameters: {'lambda': 0.009428245694437733, 'alpha': 0.0015463536069488296, 'eta': 0.0532387806315832, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 171}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2341758383633996 || TEST RMSLE : 0.769798674979374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:02:26,330] Trial 24 finished with value: 0.7907844206861944 and parameters: {'lambda': 0.06185257961377601, 'alpha': 0.00903318890988204, 'eta': 0.022736425860486482, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 176}. Best is trial 16 with value: 0.7403985413275744.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2356415337791136 || TEST RMSLE : 0.7907844206861944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:04:27,770] Trial 25 finished with value: 0.7299657526213131 and parameters: {'lambda': 0.04764282646491828, 'alpha': 0.01175260823636492, 'eta': 0.021567350323225105, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 234}. Best is trial 25 with value: 0.7299657526213131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1422083872919162 || TEST RMSLE : 0.7299657526213131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:05:50,950] Trial 26 finished with value: 0.7340027247905828 and parameters: {'lambda': 0.15182988413987902, 'alpha': 0.07996780145053656, 'eta': 0.0390100828080522, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 233}. Best is trial 25 with value: 0.7299657526213131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1493780927092703 || TEST RMSLE : 0.7340027247905828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:08:11,961] Trial 27 finished with value: 1.1010903686800644 and parameters: {'lambda': 0.12507387981597615, 'alpha': 0.13310587229742232, 'eta': 0.0176209302571826, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 294}. Best is trial 25 with value: 0.7299657526213131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4030039201655853 || TEST RMSLE : 1.1010903686800644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:08:58,147] Trial 28 finished with value: 2.027981755341995 and parameters: {'lambda': 0.5317969525322027, 'alpha': 0.04242308435199099, 'eta': 0.03564814444962369, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 17, 'min_child_weight': 231}. Best is trial 25 with value: 0.7299657526213131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.4994959491865556 || TEST RMSLE : 2.027981755341995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:10:00,828] Trial 29 finished with value: 1.3563185466548777 and parameters: {'lambda': 0.03393275866608016, 'alpha': 0.11433856894488598, 'eta': 0.025193000785836903, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 17, 'min_child_weight': 267}. Best is trial 25 with value: 0.7299657526213131.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7794662120984484 || TEST RMSLE : 1.3563185466548777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:12:11,446] Trial 30 finished with value: 0.722225726487225 and parameters: {'lambda': 0.1582024480242145, 'alpha': 0.05507624249792045, 'eta': 0.04094899840240296, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 226}. Best is trial 30 with value: 0.722225726487225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1414245485357322 || TEST RMSLE : 0.722225726487225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:14:01,837] Trial 31 finished with value: 0.725596306495561 and parameters: {'lambda': 0.16972882294985794, 'alpha': 0.05986835883912451, 'eta': 0.04392051460285981, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 231}. Best is trial 30 with value: 0.722225726487225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1396227445957718 || TEST RMSLE : 0.725596306495561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:15:27,901] Trial 32 finished with value: 0.7265879162221183 and parameters: {'lambda': 0.20508963311449818, 'alpha': 0.06263381972321912, 'eta': 0.04370501714948046, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 223}. Best is trial 30 with value: 0.722225726487225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1424359938307267 || TEST RMSLE : 0.7265879162221183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:16:40,824] Trial 33 finished with value: 0.546726622728398 and parameters: {'lambda': 0.6202804948656677, 'alpha': 0.23108156417428702, 'eta': 0.04176761650765426, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 221}. Best is trial 33 with value: 0.546726622728398.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0061312041677268 || TEST RMSLE : 0.546726622728398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:17:53,248] Trial 34 finished with value: 0.5383493289677252 and parameters: {'lambda': 1.0128210039315775, 'alpha': 0.7249260906864707, 'eta': 0.04398171564055497, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 208}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 0.9981132200306736 || TEST RMSLE : 0.5383493289677252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:18:38,672] Trial 35 finished with value: 1.0107076728708455 and parameters: {'lambda': 0.879381295665915, 'alpha': 0.9502952832074426, 'eta': 0.04119364981377637, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 17, 'min_child_weight': 260}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.517705505030538 || TEST RMSLE : 1.0107076728708455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:19:07,867] Trial 36 finished with value: 2.2894955776327675 and parameters: {'lambda': 3.1227444883723448, 'alpha': 0.23955714811126688, 'eta': 0.07213237724990083, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.01, 'n_estimators': 150, 'max_depth': 13, 'min_child_weight': 196}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.912134955663971 || TEST RMSLE : 2.2894955776327675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:20:15,383] Trial 37 finished with value: 0.7240994406847723 and parameters: {'lambda': 3.192978803931109, 'alpha': 0.5345797511517428, 'eta': 0.06492004427644214, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 210}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2567816039392046 || TEST RMSLE : 0.7240994406847723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:20:46,244] Trial 38 finished with value: 1.61319868584127 and parameters: {'lambda': 2.9970514424446915, 'alpha': 2.326683699008147, 'eta': 0.0796287669492832, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 203}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.256229155028363 || TEST RMSLE : 1.61319868584127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:21:47,612] Trial 39 finished with value: 0.7070855676649044 and parameters: {'lambda': 8.324967047223371, 'alpha': 0.5396010415866362, 'eta': 0.06476261305526713, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 220}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2789136014602394 || TEST RMSLE : 0.7070855676649044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:22:55,219] Trial 40 finished with value: 0.7120463468061612 and parameters: {'lambda': 9.587272496016704, 'alpha': 1.024370111958819, 'eta': 0.07734259339119867, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 247}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2607299472924405 || TEST RMSLE : 0.7120463468061612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:24:00,805] Trial 41 finished with value: 0.6978036973246845 and parameters: {'lambda': 7.02015200041342, 'alpha': 1.110343218399325, 'eta': 0.07784067419990333, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 272}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2621608455343558 || TEST RMSLE : 0.6978036973246845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:25:07,528] Trial 42 finished with value: 0.705528170947128 and parameters: {'lambda': 7.926148887904726, 'alpha': 8.596889715777147, 'eta': 0.07652278095173602, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 276}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2621053838725196 || TEST RMSLE : 0.705528170947128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:26:12,737] Trial 43 finished with value: 0.7095702925010319 and parameters: {'lambda': 5.834392927940444, 'alpha': 9.3595835903841, 'eta': 0.08818611177147358, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 278}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2624777225757293 || TEST RMSLE : 0.7095702925010319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:26:43,508] Trial 44 finished with value: 1.6137874705177258 and parameters: {'lambda': 5.597973433882218, 'alpha': 3.2203526585214712, 'eta': 0.07593102948824783, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 300}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.259238809864951 || TEST RMSLE : 1.6137874705177258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:27:49,573] Trial 45 finished with value: 0.7108093977994382 and parameters: {'lambda': 1.7942735092733841, 'alpha': 1.390716352346693, 'eta': 0.06549491832494367, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 271}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2614119073482697 || TEST RMSLE : 0.7108093977994382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:28:19,102] Trial 46 finished with value: 2.1106136548406957 and parameters: {'lambda': 5.843148061421489, 'alpha': 0.49430219839545914, 'eta': 0.06896079048095256, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 200, 'max_depth': 9, 'min_child_weight': 288}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.7644022862094437 || TEST RMSLE : 2.1106136548406957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:29:06,757] Trial 47 finished with value: 1.2469522845722687 and parameters: {'lambda': 0.6754523438357345, 'alpha': 5.706723682013265, 'eta': 0.08331042594366636, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 4, 'min_child_weight': 257}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7885776471822519 || TEST RMSLE : 1.2469522845722687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:29:58,277] Trial 48 finished with value: 1.0652042057746487 and parameters: {'lambda': 1.8460941433312508, 'alpha': 0.3472020589976755, 'eta': 0.09453929821565445, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 5, 'min_child_weight': 190}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6080485067310626 || TEST RMSLE : 1.0652042057746487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:31:32,460] Trial 49 finished with value: 0.5805428494090682 and parameters: {'lambda': 4.3407296411990455, 'alpha': 0.16849946836064067, 'eta': 0.04832416613811499, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 241}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.090417351292614 || TEST RMSLE : 0.5805428494090682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:32:02,669] Trial 50 finished with value: 2.475089897357266 and parameters: {'lambda': 1.8959617249516063, 'alpha': 0.17924691563918263, 'eta': 0.056934584318455314, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 150, 'max_depth': 13, 'min_child_weight': 242}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 3.109319861320157 || TEST RMSLE : 2.475089897357266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:33:34,528] Trial 51 finished with value: 0.5853802183196832 and parameters: {'lambda': 4.524312466506177, 'alpha': 0.8149704523033621, 'eta': 0.04853985025291728, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 215}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0931148155614763 || TEST RMSLE : 0.5853802183196832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:35:07,533] Trial 52 finished with value: 0.6009742090971958 and parameters: {'lambda': 3.8843582871344005, 'alpha': 0.7773761386559485, 'eta': 0.048601618992832406, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 277}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0938738501308092 || TEST RMSLE : 0.6009742090971958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:36:47,070] Trial 53 finished with value: 0.5787054518492114 and parameters: {'lambda': 4.686983964837408, 'alpha': 0.9709899112959733, 'eta': 0.04897946003542702, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 261}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.083863460035442 || TEST RMSLE : 0.5787054518492114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:38:27,439] Trial 54 finished with value: 0.6052189686386242 and parameters: {'lambda': 3.920150686035793, 'alpha': 0.7269078961906889, 'eta': 0.04888996286384404, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 261}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0788883167408942 || TEST RMSLE : 0.6052189686386242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:39:15,739] Trial 55 finished with value: 1.866467251253019 and parameters: {'lambda': 1.2905395372425774, 'alpha': 1.9290295348961508, 'eta': 0.04787847303453274, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 13, 'min_child_weight': 241}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.414526868767461 || TEST RMSLE : 1.866467251253019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:40:40,714] Trial 56 finished with value: 0.5772954183085122 and parameters: {'lambda': 0.38567749752953445, 'alpha': 0.3164401127587253, 'eta': 0.05455643432787671, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 214}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0874097663714448 || TEST RMSLE : 0.5772954183085122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:42:05,885] Trial 57 finished with value: 0.571550522701187 and parameters: {'lambda': 0.33857074991860747, 'alpha': 0.37521049640253223, 'eta': 0.05352233014713502, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 208}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0788466063347468 || TEST RMSLE : 0.571550522701187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:43:22,501] Trial 58 finished with value: 0.6809552114493287 and parameters: {'lambda': 0.3529998006020727, 'alpha': 0.17484851826207015, 'eta': 0.0545136136811191, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 160}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1940896113776387 || TEST RMSLE : 0.6809552114493287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:44:35,354] Trial 59 finished with value: 1.2980331274663217 and parameters: {'lambda': 0.44438427921727836, 'alpha': 0.3632696036426958, 'eta': 0.03641913684322552, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 13, 'min_child_weight': 186}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7063293937572546 || TEST RMSLE : 1.2980331274663217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:45:34,662] Trial 60 finished with value: 1.148324866925732 and parameters: {'lambda': 0.7928470683302533, 'alpha': 0.2515681277378859, 'eta': 0.060300655670177214, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 7, 'min_child_weight': 205}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.537019843723561 || TEST RMSLE : 1.148324866925732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:47:00,240] Trial 61 finished with value: 0.5711917366349062 and parameters: {'lambda': 0.25282717539239546, 'alpha': 0.4059266646637451, 'eta': 0.05235380441709273, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 215}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.08880209404648 || TEST RMSLE : 0.5711917366349062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:48:28,492] Trial 62 finished with value: 0.5615781334774351 and parameters: {'lambda': 0.08659640792663297, 'alpha': 0.3936421543785047, 'eta': 0.05427758191745524, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 215}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0727161786791508 || TEST RMSLE : 0.5615781334774351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 10:49:55,996] Trial 63 finished with value: 0.5651017607475666 and parameters: {'lambda': 0.08707939949859796, 'alpha': 0.48740463382031624, 'eta': 0.05304349347076083, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 197}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0707987672760928 || TEST RMSLE : 0.5651017607475666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:24:59,965] Trial 64 finished with value: 1.2513912257963133 and parameters: {'lambda': 0.07885942592617448, 'alpha': 0.4285104185781684, 'eta': 0.055556974426604955, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 196}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.54503721638024 || TEST RMSLE : 1.2513912257963133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:25:58,132] Trial 65 finished with value: 1.9817921182606415 and parameters: {'lambda': 0.2518582133252778, 'alpha': 0.28627430367233647, 'eta': 0.06180730079449234, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 200, 'max_depth': 13, 'min_child_weight': 216}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.5893107190910865 || TEST RMSLE : 1.9817921182606415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:28:35,785] Trial 66 finished with value: 1.0270053553901264 and parameters: {'lambda': 0.08600530450548535, 'alpha': 0.37095172603598164, 'eta': 0.05195936094222611, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 181}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.333859063019778 || TEST RMSLE : 1.0270053553901264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:30:22,189] Trial 67 finished with value: 0.6786309748309459 and parameters: {'lambda': 0.3109444803281117, 'alpha': 1.4746821141547277, 'eta': 0.02853009154499501, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 165}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1927279656317278 || TEST RMSLE : 0.6786309748309459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:31:41,888] Trial 68 finished with value: 1.062426468043789 and parameters: {'lambda': 0.023932647297037073, 'alpha': 0.6220874209448399, 'eta': 0.044847392945036035, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 5, 'min_child_weight': 154}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6063374489813775 || TEST RMSLE : 1.062426468043789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:32:14,143] Trial 69 finished with value: 2.3559541591465654 and parameters: {'lambda': 0.4904091971407942, 'alpha': 0.09885331116249339, 'eta': 0.05872517720487292, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 150, 'max_depth': 4, 'min_child_weight': 196}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 3.0537927238108353 || TEST RMSLE : 2.3559541591465654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:33:15,679] Trial 70 finished with value: 1.3771492293865615 and parameters: {'lambda': 0.234021025138193, 'alpha': 0.21783761823536424, 'eta': 0.05208232814467098, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 7, 'min_child_weight': 210}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.8901772403666275 || TEST RMSLE : 1.3771492293865615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:35:21,958] Trial 71 finished with value: 0.5800172411230549 and parameters: {'lambda': 0.11345611336436058, 'alpha': 0.4226691270570012, 'eta': 0.04538026646831772, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 222}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.075141851106169 || TEST RMSLE : 0.5800172411230549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:36:58,506] Trial 72 finished with value: 0.6267934268959751 and parameters: {'lambda': 0.38230675340369963, 'alpha': 0.6613287007428494, 'eta': 0.05474959885230098, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 190}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1373917530912556 || TEST RMSLE : 0.6267934268959751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:38:19,943] Trial 73 finished with value: 0.5898389610732746 and parameters: {'lambda': 0.5678055432031072, 'alpha': 0.13322884496727017, 'eta': 0.04132090669072964, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.016, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 203}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.104590421830644 || TEST RMSLE : 0.5898389610732746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:40:19,132] Trial 74 finished with value: 0.581343272086295 and parameters: {'lambda': 0.9573354887008595, 'alpha': 0.2990874739097436, 'eta': 0.03846468088600076, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 229}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0827511256055105 || TEST RMSLE : 0.581343272086295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:42:56,276] Trial 75 finished with value: 1.250091996614649 and parameters: {'lambda': 0.1744918612000651, 'alpha': 1.2680163612508129, 'eta': 0.050427724138610054, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 215}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.547252403455881 || TEST RMSLE : 1.250091996614649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:44:06,141] Trial 76 finished with value: 0.6218038275855176 and parameters: {'lambda': 0.06185393267536286, 'alpha': 0.4962106212023089, 'eta': 0.030291091237689607, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 140}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1311189150571217 || TEST RMSLE : 0.6218038275855176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:45:13,103] Trial 77 finished with value: 1.4438178555482684 and parameters: {'lambda': 0.2950837174664243, 'alpha': 2.1665629109939886, 'eta': 0.04597200004875082, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 13, 'min_child_weight': 252}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.0199950494988843 || TEST RMSLE : 1.4438178555482684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:49:00,860] Trial 78 finished with value: 0.8090982635007938 and parameters: {'lambda': 1.1272383998830942, 'alpha': 0.20502485825585545, 'eta': 0.0620735163332631, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 173}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.1900714264278425 || TEST RMSLE : 0.8090982635007938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:50:14,750] Trial 79 finished with value: 0.5753433757331355 and parameters: {'lambda': 0.12659859422997344, 'alpha': 0.9564876491424974, 'eta': 0.042589431883442, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 235}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.077942484551008 || TEST RMSLE : 0.5753433757331355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:51:00,917] Trial 80 finished with value: 1.0355433356455923 and parameters: {'lambda': 0.12346772407043705, 'alpha': 0.1421365409642626, 'eta': 0.04289170220918226, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 237}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.618505483463062 || TEST RMSLE : 1.0355433356455923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:52:20,129] Trial 81 finished with value: 0.5586143571373725 and parameters: {'lambda': 0.04101060661937289, 'alpha': 0.6227876308140678, 'eta': 0.051002898011795965, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 225}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.062835829279386 || TEST RMSLE : 0.5586143571373725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:53:34,630] Trial 82 finished with value: 0.5832409450647305 and parameters: {'lambda': 0.018899836871735548, 'alpha': 0.5601405710775011, 'eta': 0.006920182901123624, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 208}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.071148915884248 || TEST RMSLE : 0.5832409450647305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:54:47,925] Trial 83 finished with value: 0.5746042116100438 and parameters: {'lambda': 0.03403201925786231, 'alpha': 0.3050269003015248, 'eta': 0.035559519361508675, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 224}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0842186126423028 || TEST RMSLE : 0.5746042116100438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:56:30,485] Trial 84 finished with value: 0.5417748609893228 and parameters: {'lambda': 0.07494013607794574, 'alpha': 0.43765936878215705, 'eta': 0.039153566730737846, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 226}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.004718866151124 || TEST RMSLE : 0.5417748609893228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 17:58:06,956] Trial 85 finished with value: 0.5646326239246188 and parameters: {'lambda': 0.030292895470011648, 'alpha': 0.4085055903753706, 'eta': 0.036357547632410114, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 226}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.029436739192846 || TEST RMSLE : 0.5646326239246188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:00:35,405] Trial 86 finished with value: 0.9716223546213827 and parameters: {'lambda': 0.03895007984348516, 'alpha': 0.416278194274019, 'eta': 0.03281332672628525, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 202}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2929771846401623 || TEST RMSLE : 0.9716223546213827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:01:42,730] Trial 87 finished with value: 1.426499211356249 and parameters: {'lambda': 0.02633676975458844, 'alpha': 0.6624999394820591, 'eta': 0.03846290392927642, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 17, 'min_child_weight': 221}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.9676229313565137 || TEST RMSLE : 1.426499211356249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:03:15,927] Trial 88 finished with value: 0.599849981245311 and parameters: {'lambda': 0.07017604717257386, 'alpha': 0.24744168114784693, 'eta': 0.058191636910428855, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 246}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.068442792104472 || TEST RMSLE : 0.599849981245311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:06:17,526] Trial 89 finished with value: 1.060160365227827 and parameters: {'lambda': 0.015608591793823953, 'alpha': 0.4678958132742389, 'eta': 0.051553190804881306, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 181}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3694780027441114 || TEST RMSLE : 1.060160365227827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:07:58,557] Trial 90 finished with value: 0.7371566997592846 and parameters: {'lambda': 0.051322048917622015, 'alpha': 1.6460063003502032, 'eta': 0.025421895482375577, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 229}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.188326554445368 || TEST RMSLE : 0.7371566997592846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:09:41,034] Trial 91 finished with value: 0.5695963483029013 and parameters: {'lambda': 0.029355296900693044, 'alpha': 0.336403414095188, 'eta': 0.03557573609437346, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 226}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0290772565750348 || TEST RMSLE : 0.5695963483029013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:11:18,570] Trial 92 finished with value: 0.5444630382312466 and parameters: {'lambda': 0.02933360076462536, 'alpha': 0.7993806739110209, 'eta': 0.037363728981603464, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 252}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0112764211628786 || TEST RMSLE : 0.5444630382312466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:13:00,670] Trial 93 finished with value: 0.5539855593785816 and parameters: {'lambda': 0.04048637367935121, 'alpha': 0.8227082289879623, 'eta': 0.034730828634413326, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 253}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0100940550265602 || TEST RMSLE : 0.5539855593785816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:14:40,963] Trial 94 finished with value: 0.5439577189451401 and parameters: {'lambda': 0.02996314137754713, 'alpha': 0.7872095798040225, 'eta': 0.03463331628130328, 'colsample_bytree': 1.0, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 255}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0126203632161463 || TEST RMSLE : 0.5439577189451401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:16:26,311] Trial 95 finished with value: 0.5425126726630448 and parameters: {'lambda': 0.0433325632757835, 'alpha': 1.1578058693037807, 'eta': 0.029064719784225302, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 251}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.0019231507456048 || TEST RMSLE : 0.5425126726630448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:18:35,677] Trial 96 finished with value: 1.2742644937374659 and parameters: {'lambda': 0.04005324245548039, 'alpha': 1.170677621608528, 'eta': 0.027535937644132296, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 256}. Best is trial 34 with value: 0.5383493289677252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.535613883761149 || TEST RMSLE : 1.2742644937374659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:28:52,728] Trial 97 finished with value: 0.536861248368701 and parameters: {'lambda': 0.02188854135712765, 'alpha': 3.003404102231338, 'eta': 0.03095192851626769, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 251}. Best is trial 97 with value: 0.536861248368701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 0.9962630174808257 || TEST RMSLE : 0.536861248368701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:30:34,176] Trial 98 finished with value: 0.5482973645750999 and parameters: {'lambda': 0.012161275183237662, 'alpha': 3.034200549655049, 'eta': 0.03037396942239324, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 286}. Best is trial 97 with value: 0.536861248368701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.00637965003273 || TEST RMSLE : 0.5482973645750999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-06 18:32:30,328] Trial 99 finished with value: 0.8675252157718529 and parameters: {'lambda': 0.013350965357793244, 'alpha': 3.084419337083244, 'eta': 0.030628714411212694, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 289}. Best is trial 97 with value: 0.536861248368701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2501559902668147 || TEST RMSLE : 0.8675252157718529\n",
      "{'lambda': 0.02188854135712765, 'alpha': 3.003404102231338, 'eta': 0.03095192851626769, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 251}\n"
     ]
    }
   ],
   "source": [
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val), n_trials=100)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X_train, y_train, X_val, y_val, name='lgb'):\n",
    "    if name == 'lgb':\n",
    "        params = {\n",
    "            'device': 'gpu',  # using GPU\n",
    "            'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n",
    "            'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "            'feature_fraction': trial.suggest_categorical('feature_fraction', [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "            'bagging_fraction': trial.suggest_categorical('bagging_fraction', [0.6, 0.7, 0.8, 1.0]),\n",
    "            'bagging_freq': 1,  # set bagging frequency to 1 if bagging_fraction is specified\n",
    "            'learning_rate': trial.suggest_categorical('learning_rate', [0.009, 0.01, 0.012, 0.016, 0.02]),\n",
    "            'n_estimators': trial.suggest_categorical(\"n_estimators\", [150, 200, 300, 500, 1000]),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [4, 5, 7, 9, 11, 13, 17]),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n",
    "            'random_state': 10,\n",
    "            'colsample_bytree': None,\n",
    "            'reg_alpha': None,\n",
    "            'reg_lambda': None,\n",
    "            'subsample': None,\n",
    "            'subsample_freq': None\n",
    "        }\n",
    "\n",
    "        # Replace whitespaces in feature names\n",
    "        X_train.columns = [col.replace(\" \", \"_\") for col in X_train.columns]\n",
    "        X_val.columns = [col.replace(\" \", \"_\") for col in X_val.columns]\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "        predictions_train = [max(a, 0) for a in model.predict(X_train)]  # Ensure non-negative predictions\n",
    "        predictions_val = [max(a, 0) for a in model.predict(X_val)]\n",
    "\n",
    "        train_score = np.round(mean_squared_log_error(y_train, predictions_train), 5)\n",
    "        test_score = np.round(mean_squared_log_error(y_val, predictions_val), 5)\n",
    "        train_score = np.sqrt(train_score)\n",
    "        test_score = np.sqrt(test_score)\n",
    "\n",
    "        print(f'TRAIN RMSLE : {train_score} || TEST RMSLE : {test_score}')\n",
    "\n",
    "        return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:28:32,228] A new study created in memory with name: no-name-5fd1558b-cfa6-48cb-ba4b-2c1753205b22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.082907 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:28:46,000] Trial 0 finished with value: 2.182209889080333 and parameters: {'lambda_l1': 0.004725348621762896, 'lambda_l2': 0.06022157355837889, 'num_leaves': 58, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'learning_rate': 0.012, 'n_estimators': 150, 'max_depth': 7, 'min_child_weight': 220}. Best is trial 0 with value: 2.182209889080333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.865840190938776 || TEST RMSLE : 2.182209889080333\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.057655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:29:16,793] Trial 1 finished with value: 1.2288653302945771 and parameters: {'lambda_l1': 0.5015082698857507, 'lambda_l2': 0.03046991908204553, 'num_leaves': 62, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 13, 'min_child_weight': 30}. Best is trial 1 with value: 1.2288653302945771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7681996493608971 || TEST RMSLE : 1.2288653302945771\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.067550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:29:53,036] Trial 2 finished with value: 2.0593324160999362 and parameters: {'lambda_l1': 0.00489759486177691, 'lambda_l2': 0.025801821273579304, 'num_leaves': 279, 'feature_fraction': 0.6, 'bagging_fraction': 0.7, 'learning_rate': 0.016, 'n_estimators': 150, 'max_depth': 11, 'min_child_weight': 193}. Best is trial 1 with value: 1.2288653302945771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.731314701750789 || TEST RMSLE : 2.0593324160999362\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.063191 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:30:27,425] Trial 3 finished with value: 1.8493782739072069 and parameters: {'lambda_l1': 0.6108187505172783, 'lambda_l2': 0.06938959136243378, 'num_leaves': 247, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'learning_rate': 0.016, 'n_estimators': 150, 'max_depth': 11, 'min_child_weight': 129}. Best is trial 1 with value: 1.2288653302945771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.5607440325030537 || TEST RMSLE : 1.8493782739072069\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.063386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:31:04,307] Trial 4 finished with value: 1.4530381963320855 and parameters: {'lambda_l1': 0.09202888492769815, 'lambda_l2': 0.940940866141315, 'num_leaves': 297, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'learning_rate': 0.012, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 168}. Best is trial 1 with value: 1.2288653302945771.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.9946378117342507 || TEST RMSLE : 1.4530381963320855\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.076232 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:33:06,077] Trial 5 finished with value: 1.1640231956451728 and parameters: {'lambda_l1': 1.3877349804286765, 'lambda_l2': 0.09403953693542158, 'num_leaves': 96, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 31}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6347813309430714 || TEST RMSLE : 1.1640231956451728\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.080023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:33:29,692] Trial 6 finished with value: 2.270795014967225 and parameters: {'lambda_l1': 2.277369332291776, 'lambda_l2': 0.24086106916881606, 'num_leaves': 185, 'feature_fraction': 0.7, 'bagging_fraction': 0.7, 'learning_rate': 0.012, 'n_estimators': 150, 'max_depth': 17, 'min_child_weight': 154}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.9683867672525426 || TEST RMSLE : 2.270795014967225\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.059822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:34:22,051] Trial 7 finished with value: 1.1873415683787039 and parameters: {'lambda_l1': 0.09593623252153216, 'lambda_l2': 0.01939997018908697, 'num_leaves': 85, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 239}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.779404394734373 || TEST RMSLE : 1.1873415683787039\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.076152 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:38:09,701] Trial 8 finished with value: 1.2075015527940327 and parameters: {'lambda_l1': 1.93877986534703, 'lambda_l2': 0.02574630966623125, 'num_leaves': 228, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 17, 'min_child_weight': 264}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.5974730044667422 || TEST RMSLE : 1.2075015527940327\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.084489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:38:50,915] Trial 9 finished with value: 1.8007137473790775 and parameters: {'lambda_l1': 0.005381909670554375, 'lambda_l2': 0.0012885939110117972, 'num_leaves': 248, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'learning_rate': 0.016, 'n_estimators': 200, 'max_depth': 17, 'min_child_weight': 258}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.4550315680251447 || TEST RMSLE : 1.8007137473790775\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.082437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:39:42,920] Trial 10 finished with value: 1.2516828671832174 and parameters: {'lambda_l1': 6.526530564029215, 'lambda_l2': 4.750516794625059, 'num_leaves': 126, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.009, 'n_estimators': 1000, 'max_depth': 4, 'min_child_weight': 41}. Best is trial 5 with value: 1.1640231956451728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7923001980695088 || TEST RMSLE : 1.2516828671832174\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.071636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:40:42,944] Trial 11 finished with value: 1.1440104894624 and parameters: {'lambda_l1': 0.06097030607385928, 'lambda_l2': 0.003434042995219046, 'num_leaves': 117, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 9, 'min_child_weight': 94}. Best is trial 11 with value: 1.1440104894624.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7250246375052154 || TEST RMSLE : 1.1440104894624\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.075594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:42:46,986] Trial 12 finished with value: 1.1095629770319484 and parameters: {'lambda_l1': 0.036784926455384365, 'lambda_l2': 0.001927448650824274, 'num_leaves': 125, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 9, 'min_child_weight': 88}. Best is trial 12 with value: 1.1095629770319484.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.5532482093986137 || TEST RMSLE : 1.1095629770319484\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.069598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:44:00,494] Trial 13 finished with value: 1.0749092984991804 and parameters: {'lambda_l1': 0.02570782402202881, 'lambda_l2': 0.0011224355668407826, 'num_leaves': 168, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 9, 'min_child_weight': 97}. Best is trial 13 with value: 1.0749092984991804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6657070570781647 || TEST RMSLE : 1.0749092984991804\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.079029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:44:50,175] Trial 14 finished with value: 1.7400689641505591 and parameters: {'lambda_l1': 0.020766319365578254, 'lambda_l2': 0.00438239041543751, 'num_leaves': 178, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 91}. Best is trial 13 with value: 1.0749092984991804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.4317380615518607 || TEST RMSLE : 1.7400689641505591\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.074260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:45:03,615] Trial 15 finished with value: 2.1614347087062336 and parameters: {'lambda_l1': 0.0013931398344989327, 'lambda_l2': 0.0014296864228423478, 'num_leaves': 23, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'learning_rate': 0.01, 'n_estimators': 200, 'max_depth': 9, 'min_child_weight': 80}. Best is trial 13 with value: 1.0749092984991804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.859340833129202 || TEST RMSLE : 2.1614347087062336\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.067583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:46:14,184] Trial 16 finished with value: 0.9586553082312745 and parameters: {'lambda_l1': 0.02146256049901444, 'lambda_l2': 0.006513349546926397, 'num_leaves': 150, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 9, 'min_child_weight': 123}. Best is trial 16 with value: 0.9586553082312745.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6057023385422342 || TEST RMSLE : 0.9586553082312745\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.070116 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:47:19,036] Trial 17 finished with value: 0.957768239189419 and parameters: {'lambda_l1': 0.014385322181824499, 'lambda_l2': 0.008974320917670685, 'num_leaves': 160, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 9, 'min_child_weight': 139}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4327909826628586 || TEST RMSLE : 0.957768239189419\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.072544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:47:43,149] Trial 18 finished with value: 1.2559339154589304 and parameters: {'lambda_l1': 0.009871052354153073, 'lambda_l2': 0.0071675186921616825, 'num_leaves': 204, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 4, 'min_child_weight': 139}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7813562249028128 || TEST RMSLE : 1.2559339154589304\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.067365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:48:52,086] Trial 19 finished with value: 0.9831937754074728 and parameters: {'lambda_l1': 0.269141591417945, 'lambda_l2': 0.009250659978415458, 'num_leaves': 155, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 13, 'min_child_weight': 294}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4703230937450449 || TEST RMSLE : 0.9831937754074728\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.075070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:49:48,288] Trial 20 finished with value: 1.00847905283154 and parameters: {'lambda_l1': 0.0023276163384494297, 'lambda_l2': 0.22554980795505222, 'num_leaves': 153, 'feature_fraction': 0.9, 'bagging_fraction': 0.7, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 7, 'min_child_weight': 196}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4661139109905479 || TEST RMSLE : 1.00847905283154\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.066801 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:50:59,066] Trial 21 finished with value: 0.9953190443269937 and parameters: {'lambda_l1': 0.27827419509122964, 'lambda_l2': 0.008827621374487237, 'num_leaves': 158, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 13, 'min_child_weight': 295}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4642096844373076 || TEST RMSLE : 0.9953190443269937\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.066136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:52:03,541] Trial 22 finished with value: 1.019740162982708 and parameters: {'lambda_l1': 0.2164484826179985, 'lambda_l2': 0.011040423136366249, 'num_leaves': 143, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 13, 'min_child_weight': 123}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.5064195962612807 || TEST RMSLE : 1.019740162982708\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.080520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:52:35,096] Trial 23 finished with value: 1.1426591792831318 and parameters: {'lambda_l1': 0.012484546265647236, 'lambda_l2': 0.003926056175190229, 'num_leaves': 200, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 5, 'min_child_weight': 181}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6461287920451426 || TEST RMSLE : 1.1426591792831318\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.064969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:55:12,018] Trial 24 finished with value: 0.9786265886434927 and parameters: {'lambda_l1': 0.179415774692513, 'lambda_l2': 0.012396863680176404, 'num_leaves': 208, 'feature_fraction': 0.9, 'bagging_fraction': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 13, 'min_child_weight': 65}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4727457350133457 || TEST RMSLE : 0.9786265886434927\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.217495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:56:17,175] Trial 25 finished with value: 0.9618991631143048 and parameters: {'lambda_l1': 0.05489290436350974, 'lambda_l2': 0.0137724070459805, 'num_leaves': 211, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 2}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.51063562780705 || TEST RMSLE : 0.9618991631143048\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.071359 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:57:00,928] Trial 26 finished with value: 0.9698092595969581 and parameters: {'lambda_l1': 0.045354372836063646, 'lambda_l2': 0.18455529710660884, 'num_leaves': 224, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 15}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4977650015940418 || TEST RMSLE : 0.9698092595969581\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.076059 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 09:57:43,110] Trial 27 finished with value: 0.9798928512852821 and parameters: {'lambda_l1': 0.015200445703959772, 'lambda_l2': 0.0025878870926208464, 'num_leaves': 191, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 58}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.5178010409800093 || TEST RMSLE : 0.9798928512852821\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.065507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:00:02,432] Trial 28 finished with value: 1.5137205818776462 and parameters: {'lambda_l1': 0.008221924703849933, 'lambda_l2': 0.005830816866619116, 'num_leaves': 253, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 155}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.164862582243963 || TEST RMSLE : 1.5137205818776462\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.093909 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:01:02,925] Trial 29 finished with value: 1.8079712387092888 and parameters: {'lambda_l1': 0.0026503576298370765, 'lambda_l2': 0.03932823316283069, 'num_leaves': 101, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'learning_rate': 0.012, 'n_estimators': 200, 'max_depth': 7, 'min_child_weight': 5}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.500595928973732 || TEST RMSLE : 1.8079712387092888\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.201573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:03:16,801] Trial 30 finished with value: 1.9004657323929837 and parameters: {'lambda_l1': 0.029373499688025873, 'lambda_l2': 0.049966570904896555, 'num_leaves': 139, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 114}. Best is trial 17 with value: 0.957768239189419.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.581052111058589 || TEST RMSLE : 1.9004657323929837\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.177530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:04:12,084] Trial 31 finished with value: 0.9546255810525925 and parameters: {'lambda_l1': 0.05194558675772753, 'lambda_l2': 0.24294741737719266, 'num_leaves': 221, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 9}. Best is trial 31 with value: 0.9546255810525925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4969602533133604 || TEST RMSLE : 0.9546255810525925\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.067363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:05:05,982] Trial 32 finished with value: 0.9729902363333355 and parameters: {'lambda_l1': 0.09287190187162915, 'lambda_l2': 0.5084423311468415, 'num_leaves': 225, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 1}. Best is trial 31 with value: 0.9546255810525925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4991197417151174 || TEST RMSLE : 0.9729902363333355\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.084377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:06:07,969] Trial 33 finished with value: 0.9849974619256641 and parameters: {'lambda_l1': 0.057151648156927644, 'lambda_l2': 1.2546972471741042, 'num_leaves': 269, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 50}. Best is trial 31 with value: 0.9546255810525925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.4668912706809596 || TEST RMSLE : 0.9849974619256641\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.079954 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:06:55,725] Trial 34 finished with value: 1.232229686381561 and parameters: {'lambda_l1': 0.01911080780970352, 'lambda_l2': 0.015081019710928829, 'num_leaves': 168, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'learning_rate': 0.016, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 27}. Best is trial 31 with value: 0.9546255810525925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.8258422713914804 || TEST RMSLE : 1.232229686381561\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.076393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:07:08,120] Trial 35 finished with value: 1.8705453750176713 and parameters: {'lambda_l1': 0.00578296097099814, 'lambda_l2': 0.1298951869653245, 'num_leaves': 221, 'feature_fraction': 0.5, 'bagging_fraction': 0.7, 'learning_rate': 0.02, 'n_estimators': 150, 'max_depth': 5, 'min_child_weight': 221}. Best is trial 31 with value: 0.9546255810525925.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.6170575079657685 || TEST RMSLE : 1.8705453750176713\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.058695 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:08:10,371] Trial 36 finished with value: 0.8522910301065006 and parameters: {'lambda_l1': 0.14085849691701477, 'lambda_l2': 0.4047452041934976, 'num_leaves': 267, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 11, 'min_child_weight': 73}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.442716188305933 || TEST RMSLE : 0.8522910301065006\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.074907 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:08:44,270] Trial 37 finished with value: 2.12621729839638 and parameters: {'lambda_l1': 0.12799969108921996, 'lambda_l2': 0.4007732200622084, 'num_leaves': 295, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'learning_rate': 0.012, 'n_estimators': 150, 'max_depth': 11, 'min_child_weight': 137}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.785121182282739 || TEST RMSLE : 2.12621729839638\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.061465 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:09:50,430] Trial 38 finished with value: 0.9763093771955691 and parameters: {'lambda_l1': 0.5402102912750112, 'lambda_l2': 0.9565583355287194, 'num_leaves': 257, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.016, 'n_estimators': 300, 'max_depth': 11, 'min_child_weight': 117}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.6098695599333508 || TEST RMSLE : 0.9763093771955691\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.092424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:10:37,909] Trial 39 finished with value: 1.155209937630386 and parameters: {'lambda_l1': 0.380886263599826, 'lambda_l2': 1.6628871843597557, 'num_leaves': 276, 'feature_fraction': 1.0, 'bagging_fraction': 0.7, 'learning_rate': 0.02, 'n_estimators': 200, 'max_depth': 11, 'min_child_weight': 70}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.8074982710918426 || TEST RMSLE : 1.155209937630386\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.055327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:12:27,002] Trial 40 finished with value: 1.3161003001291354 and parameters: {'lambda_l1': 0.7744051092664967, 'lambda_l2': 2.404551568638294, 'num_leaves': 237, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'learning_rate': 0.012, 'n_estimators': 500, 'max_depth': 11, 'min_child_weight': 108}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7798005506235803 || TEST RMSLE : 1.3161003001291354\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.077374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:13:15,513] Trial 41 finished with value: 1.0014289790094952 and parameters: {'lambda_l1': 0.05759650367146039, 'lambda_l2': 0.07500790894591422, 'num_leaves': 175, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 23}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.549348250071623 || TEST RMSLE : 1.0014289790094952\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.072772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:13:35,578] Trial 42 finished with value: 1.5002133181651203 and parameters: {'lambda_l1': 0.16439571283386192, 'lambda_l2': 0.028518568917981355, 'num_leaves': 194, 'feature_fraction': 0.5, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 4, 'min_child_weight': 42}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.0400686262966743 || TEST RMSLE : 1.5002133181651203\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.050705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:14:16,051] Trial 43 finished with value: 1.2159481896857283 and parameters: {'lambda_l1': 0.09023145850627158, 'lambda_l2': 0.3506493378078081, 'num_leaves': 265, 'feature_fraction': 0.7, 'bagging_fraction': 0.8, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 7, 'min_child_weight': 15}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.7479530886153667 || TEST RMSLE : 1.2159481896857283\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.066991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:15:19,667] Trial 44 finished with value: 1.636758992643694 and parameters: {'lambda_l1': 0.026605910020988614, 'lambda_l2': 0.12525455239906091, 'num_leaves': 241, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'learning_rate': 0.009, 'n_estimators': 300, 'max_depth': 9, 'min_child_weight': 166}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 2.304508624414324 || TEST RMSLE : 1.636758992643694\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.085012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:19:03,797] Trial 45 finished with value: 0.8869103675118473 and parameters: {'lambda_l1': 0.04629962693167496, 'lambda_l2': 0.5593301011537876, 'num_leaves': 287, 'feature_fraction': 0.9, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 37}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3806266693063698 || TEST RMSLE : 0.8869103675118473\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.085716 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:22:55,059] Trial 46 finished with value: 0.8899550550449162 and parameters: {'lambda_l1': 0.007885587145741368, 'lambda_l2': 0.5769240488216735, 'num_leaves': 288, 'feature_fraction': 0.9, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 38}. Best is trial 36 with value: 0.8522910301065006.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.3808185977890073 || TEST RMSLE : 0.8899550550449162\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.060185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:26:57,216] Trial 47 finished with value: 0.8337025848586533 and parameters: {'lambda_l1': 0.0058895657225990486, 'lambda_l2': 0.5424611706388938, 'num_leaves': 287, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 44}. Best is trial 47 with value: 0.8337025848586533.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.293928127834 || TEST RMSLE : 0.8337025848586533\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.076145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:30:37,155] Trial 48 finished with value: 0.8301927487035767 and parameters: {'lambda_l1': 0.002900639384968933, 'lambda_l2': 0.5505333870677505, 'num_leaves': 291, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 47}. Best is trial 48 with value: 0.8301927487035767.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.290565767405908 || TEST RMSLE : 0.8301927487035767\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 860\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) Iris(R) Xe Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 16 dense feature groups (44.54 MB) transferred to GPU in 0.061475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 354.309666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-07 10:34:21,624] Trial 49 finished with value: 0.8019351594736323 and parameters: {'lambda_l1': 0.0038625695120410065, 'lambda_l2': 0.8017534786386871, 'num_leaves': 290, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 37}. Best is trial 49 with value: 0.8019351594736323.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN RMSLE : 1.2961134209628415 || TEST RMSLE : 0.8019351594736323\n",
      "{'lambda_l1': 0.0038625695120410065, 'lambda_l2': 0.8017534786386871, 'num_leaves': 290, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 37}\n"
     ]
    }
   ],
   "source": [
    "# Create a study object and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(lambda trial: objective(trial, X_train, y_train, X_val, y_val, 'lgb'), n_trials=50)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lambda': 0.02188854135712765, 'alpha': 3.003404102231338, 'eta': 0.03095192851626769, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.02, 'n_estimators': 500, 'max_depth': 17, 'min_child_weight': 251}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XGBRegressor model with the specified parameters\n",
    "xgboost_opt = XGBRegressor(**params)\n",
    "\n",
    "# Callback for early stopping\n",
    "early_stop = [xgb.callback.EarlyStopping(rounds=50, save_best=True)]\n",
    "\n",
    "# Fit the model\n",
    "xgboost_opt.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, callbacks=early_stop)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xgboost_opt.predict(X_val)\n",
    "actual = y_val\n",
    "predictions[predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and read xgboost model data as pkl file\n",
    "with open('models/m2_xgboost.pkl', 'wb') as file:\n",
    "    pickle.dump(xgboost_opt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/m2_xgboost.pkl', 'rb') as file:\n",
    "    xgb_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcMetrics(testActualVal, predictions):\n",
    "    #regression evaluation measures\n",
    "    data={\"RMSLE\":[mean_squared_log_error(testActualVal, predictions)**0.5],\n",
    "         \"MAE\":[mean_absolute_error(testActualVal, predictions)],\n",
    "         \"RMSE\":[mean_squared_error(testActualVal, predictions)**0.5],\n",
    "         \"R2\":[r2_score(testActualVal, predictions)]}\n",
    "    metric_df=pd.DataFrame(data)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539186</td>\n",
       "      <td>97.358329</td>\n",
       "      <td>341.212114</td>\n",
       "      <td>0.933007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSLE        MAE        RMSE        R2\n",
       "0  0.539186  97.358329  341.212114  0.933007"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcMetrics(actual, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lambda_l1': 0.0038625695120410065, 'lambda_l2': 0.8017534786386871, 'num_leaves': 290, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'learning_rate': 0.01, 'n_estimators': 1000, 'max_depth': 11, 'min_child_weight': 37}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0038625695120410065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0038625695120410065\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8017534786386871, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8017534786386871\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0038625695120410065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0038625695120410065\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8017534786386871, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8017534786386871\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 870\n",
      "[LightGBM] [Info] Number of data points in the train set: 2918916, number of used features: 52\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0038625695120410065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0038625695120410065\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8017534786386871, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8017534786386871\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Info] Start training from score 354.309666\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0038625695120410065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0038625695120410065\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8017534786386871, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8017534786386871\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n"
     ]
    }
   ],
   "source": [
    "# Create the LightGBM Regressor model with the specified parameters\n",
    "lightgbm_opt = lgb.LGBMRegressor(**params)\n",
    "\n",
    "# Fit the model\n",
    "lightgbm_opt.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Make predictions\n",
    "predictions = lightgbm_opt.predict(X_val)\n",
    "actual = y_val\n",
    "predictions[predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and read lightgbm model data as pkl file\n",
    "with open('models/m3_lightgbm.pkl', 'wb') as file:\n",
    "    pickle.dump(lightgbm_opt, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/m3_lightgbm.pkl', 'rb') as file:\n",
    "    lightgbm_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSLE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800275</td>\n",
       "      <td>101.284878</td>\n",
       "      <td>342.119995</td>\n",
       "      <td>0.93265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RMSLE         MAE        RMSE       R2\n",
       "0  0.800275  101.284878  342.119995  0.93265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcMetrics(actual, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_pickle('processed_data/train_df.pkl')\n",
    "X_test = test_df[COL_NAMES_ORIGINAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0038625695120410065, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0038625695120410065\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.8017534786386871, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.8017534786386871\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n"
     ]
    }
   ],
   "source": [
    "# preprocess test dataset\n",
    "X_test = preprocess_pipe.transform(X_test)\n",
    "\n",
    "# xgboost\n",
    "final_predictions_xgb = xgb_model.predict(X_test)\n",
    "final_predictions_xgb[final_predictions_xgb < 0] = 0\n",
    "test_df['final_predictions_xgb'] = final_predictions_xgb\n",
    "\n",
    "# lightgbm\n",
    "final_predictions_lgb = lightgbm_model.predict(X_test)\n",
    "test_df['final_predictions_lgb'] = final_predictions_lgb\n",
    "final_predictions_lgb[final_predictions_lgb < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('test_with_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>typeholiday</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>typestores</th>\n",
       "      <th>cluster</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>final_predictions_xgb</th>\n",
       "      <th>final_predictions_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.217876</td>\n",
       "      <td>-4.224551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.370709</td>\n",
       "      <td>-4.671350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>93.14</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.482602</td>\n",
       "      <td>-4.831892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      family  sales  onpromotion typeholiday  dcoilwtico   city  \\\n",
       "0 2013-01-01  AUTOMOTIVE    0.0            0     Holiday       93.14  Quito   \n",
       "1 2013-01-01   BABY CARE    0.0            0     Holiday       93.14  Quito   \n",
       "2 2013-01-01      BEAUTY    0.0            0     Holiday       93.14  Quito   \n",
       "\n",
       "       state typestores  cluster  day_of_week  month  year  \\\n",
       "0  Pichincha          D       13            2      1  2013   \n",
       "1  Pichincha          D       13            2      1  2013   \n",
       "2  Pichincha          D       13            2      1  2013   \n",
       "\n",
       "   final_predictions_xgb  final_predictions_lgb  \n",
       "0               0.217876              -4.224551  \n",
       "1              -1.370709              -4.671350  \n",
       "2               0.482602              -4.831892  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
